{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ocean_DeepLearning_09_02_2021.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMlHttfmmWs2a2ONnQtrukv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGemaque/ocean-backend-nuvem-04-02-2021/blob/main/Ocean_DeepLearning_09_02_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvlyUnfB2PSh"
      },
      "source": [
        "import keras # Importa a biblioteca Keras\r\n",
        "from keras.datasets import mnist # Base de Dados MNIST\r\n",
        "from tensorflow.python.keras import Sequential # Arquitetura da nossa rede neura\r\n",
        "from tensorflow.python.keras.layers import Dense, Dropout # Neurônio (base da rede) e Regularizador (evita overfitting)\r\n",
        "from tensorflow.compat.v1.keras.optimizers import RMSprop # Otimizador (back propagation)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_dizi0P8J6n",
        "outputId": "bffd36f1-5ed3-43e9-c1de-b8278710d021"
      },
      "source": [
        "# Carregando os dados de treino e teste\r\n",
        "\r\n",
        "(x_treino, y_treino), (x_teste, y_teste)= mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaNFe-ZC-nW9",
        "outputId": "6d53c2ec-f1bc-4132-a2ab-834559859569"
      },
      "source": [
        "# Após importar os dados, é importante dar uma analisada para ver o que temos no dataset\r\n",
        "# e como ele está estruturado\r\n",
        "\r\n",
        "print(\"Quantidade de imagens para treino:\", len(x_treino))\r\n",
        "\r\n",
        "print(\"Quantidade de imagens para teste:\", len(x_teste))\r\n",
        "\r\n",
        "print(\"Tipo de x_treino:\", type(x_treino))\r\n",
        "\r\n",
        "primeira_imagem = x_treino[0]\r\n",
        "\r\n",
        "representacao_primeira_imagem = y_treino[0]\r\n",
        "\r\n",
        "print(\"O que a imagem 0 representa:\", representacao_primeira_imagem)\r\n",
        "\r\n",
        "print(\"Formato da primeira imagem:\", primeira_imagem.shape, type(primeira_imagem.shape))\r\n",
        "\r\n",
        "print(primeira_imagem)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de imagens para treino: 60000\n",
            "Quantidade de imagens para teste: 10000\n",
            "Tipo de x_treino: <class 'numpy.ndarray'>\n",
            "O que a imagem 0 representa: 5\n",
            "Formato da primeira imagem: (28, 28) <class 'tuple'>\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "YBNlHkTLDPg_",
        "outputId": "cbc35321-ca97-4b6e-8447-717c2dfdff32"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "indice = 12000\r\n",
        "\r\n",
        "print(\"a imagem representa:\", y_treino[indice])\r\n",
        "\r\n",
        "plt.imshow(x_treino[indice], cmap=plt.cm.binary)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a imagem representa: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f17b4f12dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdnvSVboEulA"
      },
      "source": [
        "# Fluxo para construção de rede neural\r\n",
        "# - Organizar a camada de entrada (input)\r\n",
        "# - Organizar a camada de saída (output)\r\n",
        "# - Estruturar a nossa rede neural\r\n",
        "# - Treinar o modelo\r\n",
        "# - Fazer as previsões\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiq1hX9zE8Nj"
      },
      "source": [
        "# Achatando a matriz de pixels e transformando em uma única lista\r\n",
        "\r\n",
        "quantidade_treino = len(x_treino) #6000\r\n",
        "quantidade_teste = len(x_teste) #10000\r\n",
        "\r\n",
        "resolucao_imagem = x_treino[0].shape # (28,28)\r\n",
        "\r\n",
        "resolucao_total = resolucao_imagem[0] * resolucao_imagem[1] # 28 * 28 = 784\r\n",
        "\r\n",
        "x_treino = x_treino.reshape(quantidade_treino, resolucao_total)\r\n",
        "x_teste = x_teste.reshape(quantidade_teste, resolucao_total)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGVNITMLGfnr",
        "outputId": "b7a90e10-4992-4dc0-c511-8fd32ce1f3d5"
      },
      "source": [
        "print(\"Quantidade de itens em x_treino_achatado[0]\", len(x_treino[0]))\r\n",
        "\r\n",
        "#Como ficou x_treino_achatado[0]\r\n",
        "print(x_treino[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de itens em x_treino_achatado[0] 784\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Quog_CH1ij"
      },
      "source": [
        "# Normalização dos dados\r\n",
        "\r\n",
        "# 255 vire 1\r\n",
        "#127 vire 0.5\r\n",
        "# 0 vire 0\r\n",
        "# E assim por diante\r\n",
        "\r\n",
        "x_treino = x_treino.astype('float32') # Converte toda a base de x_treino de uint_8 para float32\r\n",
        "x_teste = x_teste.astype('float32') # Converte toda a base de x_teste de uint_8 para float32\r\n",
        "\r\n",
        "x_treino /= 255 # x_treino = x_treino/255, divide os 60000 valores\r\n",
        "x_teste /= 255 # x_teste = x_teste/255, divide os 10000 valores"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MsGsZ-gO52b",
        "outputId": "dce54cec-8832-483a-88b6-263fe333a78f"
      },
      "source": [
        "# Acessamos a primeria imagem, disponível em x_treino[0], e depos exibimos qual o valor está no pixel 350 da imagem\r\n",
        "# Lembando que cada linha possui 28 pixels (0-27), portanto ao acessar o índice 28, estamos acessando o primeiro pixel da segunda linha.\r\n",
        "\r\n",
        "print(x_treino[0][350], type(x_treino[0][350]))\r\n",
        "print(x_treino[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27450982 <class 'numpy.float32'>\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBY4-JvJTPy2",
        "outputId": "dde90fba-b42c-4c09-bf3b-d5a762c8adcd"
      },
      "source": [
        "# Preparação da camada de saída (output)\r\n",
        "\r\n",
        "# Quais são as possibilidades de saída? Números de 0 a 9\r\n",
        "# Quantos itens temos? 10 itens\r\n",
        "# Números -> [0,1,2,3,4,5,6,7,8,9]\r\n",
        "# Número 0 -> [1,0,0,0,0,0,0,0,0,0]\r\n",
        "# Número 1 -> [0,1,0,0,0,0,0,0,0,0]\r\n",
        "# Número 9 -> [0,0,0,0,0,0,0,0,0,1]\r\n",
        "\r\n",
        "valores_unicos = set(y_treino) # {0,1,2,3,4,5,6,7,8,9}\r\n",
        "print(valores_unicos)\r\n",
        "\r\n",
        "quantidade_valores_unicos = len(valores_unicos) # 10\r\n",
        "print(quantidade_valores_unicos)\r\n",
        "\r\n",
        "print(\"y_treino[0] antes:\", y_treino[0])\r\n",
        "\r\n",
        "y_treino = keras.utils.to_categorical(y_treino, quantidade_valores_unicos)\r\n",
        "y_teste = keras.utils.to_categorical(y_teste, quantidade_valores_unicos)\r\n",
        "\r\n",
        "print(\"y_treino[0] depois:\", y_treino[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10\n",
            "y_treino[0] antes: 5\n",
            "y_treino[0] depois: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VetW5QMyVVGT",
        "outputId": "2ddcbbda-768e-4de0-9fd8-53cb577b1ba5"
      },
      "source": [
        "# Criando o modelo da rede neural\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Primeira hidden layer\r\n",
        "# 30 neurônios\r\n",
        "# Função de ativação: ReLU\r\n",
        "# Como estamos na primeira hidden layer, precisamos informar o formato da camada de entrada (input)\r\n",
        "\r\n",
        "model.add(Dense(30, activation='relu', input_shape=(resolucao_total,)))\r\n",
        "\r\n",
        "# Adicionamos um regularizador, que ajuda a evitar o overfitting\r\n",
        "# No caso, será o Dropout\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# Segunda hidden layer\r\n",
        "# 20 neurônios\r\n",
        "# Função de ativação: ReLU\r\n",
        "\r\n",
        "model.add(Dense(20, activation='relu'))\r\n",
        "\r\n",
        "# Mais um regularizador depois da segunda hidden layer\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# Finalizamos com a camada de saída (output), informando a quantidade de valores únicos que, no caso, é 10\r\n",
        "# Função de ativação: Como ReLU  deve ser usada apenas nas hidden layers, iremos utilizar a função Softmax\r\n",
        "model.add(Dense(quantidade_valores_unicos, activation='softmax'))\r\n",
        "\r\n",
        "# Exibe o resumo do modelo criado\r\n",
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 24,380\n",
            "Trainable params: 24,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqGXJtnJZ16O",
        "outputId": "18227dcf-599f-4de7-9960-c439abcf3d84"
      },
      "source": [
        "# Compila e treina o modelo\r\n",
        "# Precisamos informar qual será:\r\n",
        "# Função de erro\r\n",
        "# Algoritmo de backpropagation\r\n",
        "# Dados para Treino (imagens normalizadas e labels categorizadas)\r\n",
        "# Dados para Teste (imagens normalizadas e labels categorizadas)\r\n",
        "# Quantidade de épocas que queremos rodar (sendo 1 época equivalente a analisar TODAS as imagens de treino)\r\n",
        "# Tamanho de cada 'batch'\r\n",
        "#   -> Supondo que temos 100 imagens\r\n",
        "#   -> 100 imagens pode ser muito pesado para processar de uma única vez\r\n",
        "#   -> Portanto, quebramos em 'batches' de 10 imagens, cada, e processamos 10 imagens por vez\r\n",
        "#   -> Geralmente, o tamanho dos batches deve ser potência de 2 (2, 4, 8, 16, 32, 64, 128, ...), para melhorar performance\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=RMSprop(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# Treina o modelo\r\n",
        "\r\n",
        "history = model.fit(x_treino, y_treino,\r\n",
        "                    batch_size=128,\r\n",
        "                    epochs=10,\r\n",
        "                    verbose=1,\r\n",
        "                    validation_data=(x_teste, y_teste))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 4ms/step - loss: 1.1870 - accuracy: 0.6122 - val_loss: 0.2979 - val_accuracy: 0.9158\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.4889 - accuracy: 0.8524 - val_loss: 0.2315 - val_accuracy: 0.9323\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3960 - accuracy: 0.8825 - val_loss: 0.2077 - val_accuracy: 0.9384\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3557 - accuracy: 0.8962 - val_loss: 0.1964 - val_accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3313 - accuracy: 0.9039 - val_loss: 0.1821 - val_accuracy: 0.9458\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3079 - accuracy: 0.9102 - val_loss: 0.1778 - val_accuracy: 0.9482\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2994 - accuracy: 0.9134 - val_loss: 0.1689 - val_accuracy: 0.9501\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2902 - accuracy: 0.9160 - val_loss: 0.1670 - val_accuracy: 0.9501\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2826 - accuracy: 0.9175 - val_loss: 0.1614 - val_accuracy: 0.9532\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2676 - accuracy: 0.9216 - val_loss: 0.1619 - val_accuracy: 0.9552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "EwL3bXSpbqE8",
        "outputId": "e3668b8a-8091-4f81-ea16-c61f53f9bb36"
      },
      "source": [
        "#Fazend nossas previsões\r\n",
        "\r\n",
        "indice = 1234\r\n",
        "\r\n",
        "print(\"Valor categórico em y_teste[indice]:\", y_teste[indice])\r\n",
        "\r\n",
        "imagem = x_teste[indice].reshape(1,resolucao_total)\r\n",
        "\r\n",
        "# Fazemos a previsão da imagem\r\n",
        "prediction = model.predict(imagem)\r\n",
        "print(\"Previsão:\", prediction)\r\n",
        "\r\n",
        "# Transformar a previsão em algo que conseguimos entender de forma mais fácil\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "# Convertemos a previsão que está em %, pegando o maior valor disponível\r\n",
        "prediction_class = np.argmax(prediction, axis=-1)\r\n",
        "print(\"Previsão ajustada:\", prediction_class)\r\n",
        "\r\n",
        "# Recarregamos o MNIST e exibimos a imagem original usando o matplotlib carregado anteriormente\r\n",
        "(x_treino_img, y_treino_img), (x_teste_img, y_teste_img) = mnist.load_data()\r\n",
        "plt.imshow(x_teste_img[indice], cmap=plt.cm.binary)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor categórico em y_teste[indice]: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "Previsão: [[0.00351723 0.00361175 0.0095517  0.03162069 0.00149949 0.0434482\n",
            "  0.00162122 0.00426636 0.8797923  0.02107111]]\n",
            "Previsão ajustada: [8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f17ad43ce10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}